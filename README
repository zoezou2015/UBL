This is implementation in Java for paper "Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification".
The code is published by authors. This version is slightly modified to support multilingual corpus 
(only loading path part is changed).

To run the parser, two arguments need provided, the inintial lexicon learnt by GIZA++ and language

Two options to start learning parser:
1. Export .java files into .jar, and run command
java -Xmx1500m -Djava.library.path=/usr/local/lib -cp TestTrain.jar TestTrain sv-np-fixedlex.geo sv > run_sv.test

2. Compile TestTrain.java and run command 
java -Xmx1500m TestTrain sv-np-fixedlex.geo sv > run_sv.test

The output will be written to file "run_sv.test"

The fixed lexicon is necessary for such algorithm. The file Run_GIZA++ contains all commands for 
learning fixed lexicon for four geo880-funql lingual corpus

############################################################
The following is original README content provided by authors

To run fold i of the 10 fold cross validation on the 600 sentence 
development set:
	
	./rundev.pl i

To train on the full development set and test on the 280
example test set:

	./runtest.pl


Options are set in DevTrain.java for development runs and 
TestTrain.java for test runs. Details below.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Inputs:

------------------------------
Training and test data made up of sentence, logical-form 
pairs such as:
	
	what is the highest point in the us
	(argmax $0 (and (place:t $0) (loc:t $0 usa:co)) (elevation:i $0))

------------------------------

File of word, constant co-occurence statistics. One const, word
pair per line with format:

	const  ::  word  ::  probability

------------------------------

Initial NP lexicon (optional) with one lexical item per line:

	word :- NP : logical-form

------------------------------

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Options (in DevTrain and TestTrain).

Train.emptytest : defines whether or not word skipping
		  is allowed at test time.

Train.EPOCHS 	: number of iterations.

Train.alpha_0 
Train.c 	: for parameter update temperatures.

Train.verbose	: print out details of training and 
		  testing.

Train.initWeightMultiplier : scaling for co-occurence
			     probabilities

Train.initLexMultiplier	: initial weight for items in NP 
			  list.

parser.pruneN	: beam width for parser

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

